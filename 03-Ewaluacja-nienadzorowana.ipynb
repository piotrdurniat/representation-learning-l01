{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55246e5",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ce516",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c9258",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bcf48-1678-4bd4-8d6c-a0607ad34066",
   "metadata": {},
   "source": [
    "# Zadanie 6 Ewaluacja nienadzorowana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c47882-8fce-48ee-a0a9-dea1d9481fa8",
   "metadata": {},
   "source": [
    "Metody ewaluacji w poprzednim zeszycie opierały się na zastosowaniu reprezentacji w zadaniu docelowym. O ile ten rodzaj ewaluacji stanowi podstawę w przypadku badania jakości nienadzorowanych metod, to ma pewne ograniczenia:\n",
    "1. Ewaluacja taka może okazać się kosztowna, sczczególnie jeśli sprawdzamy się na dużym zbiorze i chcemy mieć podgląd w trakcie uczenia, np. co epokę\n",
    "2. Ewaluacja na zadaniu docelowym nie dostarcza nam wszystkich informacji na temat jakości reprezentacji, np. tego czy w pełni wykorzystujemy wszystkie wymiary reprezentacji i model nie wyuczył się redundantnych cech\n",
    "\n",
    "Ewaluacja reprezentacji w sposób nienadzorowany (nie na zadaniu docelowym) najczęściej korzysta z metod probabilistycznych i/lub algebry liniowej [(Tsitsulin et al., 2023)](https://arxiv.org/pdf/2202.05808.pdf). W niniejszym zeszycie należy zaimplementować dwie metody takiej ewaluacji, przy okazji odświeżając sobie zagadnienia z algebry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422013a7-24f6-4db7-bafb-e0e9fe994e70",
   "metadata": {},
   "source": [
    "## Zadanie 6.1 (1 pkt)\n",
    "W pierwszej kolejności sprawdzimy jak mocno reprezentacje uległy zjawisku zapadnięcia się wymiarów (ang. *dimensional collapse*). Do tego wykorzystamy spektrum wartości własnych (ang. *eigenvalues*) macierzy kowariancji. **Wymagane jest pełne zrozumienie istoty takiej ewaluacji, czyli tego czym są macierze, wektory i wartości własne, oraz macierz kowariancji.** W tym celu można skorzystać z serii [Essence of Linear Algebra](https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&si=Zy91Y6-vUxiYOWeQ) i wymienionej powyżej pracy. \n",
    "\n",
    "Uzupełnij poniższą funkcję `compute_cov_eig`, która wyliczy spektrum wartości własnych z macierzy kowariancji reprezentacji (posortowane). Czy przed wyznaczeniem macierzy kowariancji należy wycentrować lub ustandaryzować wektory reprezentacji? Zinterpretuj otrzymany wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2d72a-8e80-41c6-913e-242b8b11439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8531e39-a54e-4f6c-bf99-b6202afa7917",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c759da7351c6e42e07f938277ddc384f",
     "grade": true,
     "grade_id": "eigenspectrum",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_cov_eig(z: Tensor) -> Tensor:\n",
    "    # TU WPISZ KOD\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3baa685-f95a-494d-9cc3-aeb6c52f66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = torch.load(\"z_train.pt\")\n",
    "eigval_spectrum = compute_cov_eig(z_train).cpu().numpy()\n",
    "\n",
    "eigval_idx = np.arange(len(eigval_spectrum))\n",
    "ax = sns.lineplot(x=eigval_idx, y=eigval_spectrum)\n",
    "ax.set(xlabel=\"Sorted eigenvalue index\", ylabel=\"eigenvalue\", title=\"Eigenspectrum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68217b4a-d68a-4106-ba2c-c0fd0d2cfb85",
   "metadata": {},
   "source": [
    "## Zadanie 6.3 (0.5 pkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c202c-09d4-469a-9b02-639c837559aa",
   "metadata": {},
   "source": [
    "Wyżej otrzymane spektrum może posłużyć analizie i porównaniom różnych reprezentacji. Często jednak zamiast spektrum chcielibyśmy otrzymać pojedynczą wartość jako miarę jakości reprezentacji. Przykładowo powyższą krzywą można dopasować do rokładu *power-law* ($\\lambda_j \\propto j^{-\\alpha},$ gdzie $\\lambda_j$ jest $j$-tą wartością własną, a $\\alpha$ współczynnikiem zanikania (ang. *coefficient of decay*)), a otrzymany współczynnik potraktować jako taką miarę [(Gosh et al., 2022)](https://arxiv.org/abs/2202.05808).\n",
    "\n",
    "Dużo prostszym i jednocześnie skuteczniejszym podejściem jest metoda $\\texttt{RankMe}$ [(Garrido et al., 2022)](https://arxiv.org/abs/2210.02885), która pozwala na estymacje rzędu (ang. *rank*) macierzy reprezetacji na podstawie entropii rozkładu wartości osobliwych (ang. *signular values* z metody [*Singular Value Deocomposition (SVD)*](https://en.wikipedia.org/wiki/Singular_value_decomposition)), co sprowadza się do poniższego wzoru:\n",
    "$$\\texttt{RankMe}(\\boldsymbol{Z}) = exp \\left(- \\sum_{k=1}^{min(N, D)} p_klog p_k \\right)$$\n",
    "$$p_k = \\frac{\\sigma_k(\\boldsymbol{Z})}{\\lVert \\sigma_k(\\boldsymbol{Z}) \\rVert_1} + \\epsilon$$\n",
    "gdzie\n",
    "$\\boldsymbol{Z}$ - macierz reprezentacji $(N, D)$, $\\sigma_k(\\boldsymbol{Z}$ - $k$-ta wartość osobliwa, $\\epsilon$ - mała wartość dla stabilności obliczeń\n",
    "\n",
    "Zaimplementuj funkcję `rank_me` wykorzystując powyższy wzór. **Wymagane jest pełne zrozumienie metody, w szczególności pojęć: SVD, entropii oraz rzędu macierzy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830bd17-3524-4c08-b9cd-ea126726ed66",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9013e64f8d1226395ceb7f928611c80e",
     "grade": true,
     "grade_id": "rank-me",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TU WPISZ KOD\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88021df-57e6-4510-ad96-a32f8815747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_me(z_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11d485-293a-4403-b523-000c3340a782",
   "metadata": {},
   "source": [
    "## Zadanie 6.2 (0.5 pkt)\n",
    "Wepnij metodę estymacji rzędu w pętli uczenia, tak aby końcowo wykreślić zmianę tej metryki w funkcji epoki:\n",
    "1. Skopiuj implementacje autokodera z poprzedniego zeszytu i zadbaj o to, aby funkcja `forward` oprócz rekonstrukcji zwracała również reprezentację\n",
    "2. Dokonaj modyfikacji funkcji `train`, tak aby wyliczała rząd macierzy reprezentacji zwróconej przez funkcję `forward`. Zwróć uwagę, że wykorzystujemy tutaj tylko jedną paczkę (ang. *batch*) danych, co stanowi ułatwienie (w przypadku wielu batch'y w epoce, należałoby zadbać o odpowiednia agregację)\n",
    "3. Uruchom proces uczenia i sprawdź rezultat. Czy wykres zmian rzędu macierzy w procese uczenia zawsze jest taka sam na przestrzeni kilku uruchomień?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a355f80-71d0-44b2-bcd9-dfd7b3934add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X = X / 16.  # Każda cecha ma zakres wartości 0-16\n",
    "\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df78e1-33a5-4da8-b453-7e3f30ee0df9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b96d6733f9c9b20b41395fd495df1e1",
     "grade": true,
     "grade_id": "ae-return-repr",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaee718-fa2f-4de0-b9d5-9bea7353d8fa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac7f72b730bd7f58e4d4fe1513faf9ba",
     "grade": true,
     "grade_id": "ae-register-rank",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "    \n",
    "    \n",
    "def train(\n",
    "    model: Autoencoder, \n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    x: torch.Tensor,\n",
    ") -> tuple[float, float]:\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x_rec, z = model(x)\n",
    "    loss = F.mse_loss(input=x_rec, target=x)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # TU WPISZ KOD\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return loss.item(), rank.item()\n",
    "\n",
    "\n",
    "def test(model: Autoencoder, x: torch.Tensor) -> float:\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_rec, _ = model(x)\n",
    "        loss = F.mse_loss(input=x_rec, target=x)\n",
    "        \n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9091c9e-c148-4e1c-81fe-ba7e4a66b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm    \n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "REPRESENTATION_DIM = 8\n",
    "\n",
    "\n",
    "ae = Autoencoder(feature_dim=X.shape[1], hidden_dim=REPRESENTATION_DIM)\n",
    "opt = torch.optim.Adam(ae.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "train_ranks = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ae = ae.to(DEVICE)\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"Epochs\"):\n",
    "    X_train = X_train.to(DEVICE)\n",
    "    X_test = X_test.to(DEVICE)\n",
    "    train_loss, train_rank = train(model=ae, optimizer=opt, x=X_train)\n",
    "    test_loss = test(model=ae, x=X_test)\n",
    "\n",
    "    train_ranks.append(train_rank)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "fig, (ax_loss, ax_rank) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax_loss.plot(train_losses, label=\"Train\")\n",
    "ax_loss.plot(test_losses, label=\"Test\")\n",
    "ax_loss.set(title=\"Loss\", xlabel=\"Epochs\", ylabel=\"Loss\")\n",
    "fig.legend()\n",
    "\n",
    "ax_rank.plot(train_ranks)\n",
    "ax_rank.set(title=\"Representation rank\", xlabel=\"Epoch\", ylabel=\"Estimated rank\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
